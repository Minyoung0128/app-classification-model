{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/myk/min0/')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import preprocess as pp\n",
    "import cwe\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed) #torch를 거치는 모든 난수들의 생성순서를 고정한다\n",
    "    torch.cuda.manual_seed(seed) #cuda를 사용하는 메소드들의 난수시드는 따로 고정해줘야한다 \n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True #딥러닝에 특화된 CuDNN의 난수시드도 고정 \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed) #numpy를 사용할 경우 고정\n",
    "    random.seed(seed) #파이썬 자체 모듈 random 모듈의 시드 고정\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 is arkio\n",
      "1 is bigballers\n",
      "2 is bigscreen\n",
      "3 is blaston\n",
      "4 is campfire\n",
      "5 is epicrollercoasters\n",
      "6 is firsthand\n",
      "7 is firsttouch\n",
      "8 is fitxr\n",
      "9 is godsofgravity\n",
      "10 is gorillatag\n",
      "11 is gunraiders\n",
      "12 is horizonworkrooms\n",
      "13 is horizonworlds\n",
      "14 is hyperdash\n",
      "15 is immersed\n",
      "16 is netflix\n",
      "17 is roblox\n",
      "18 is vrchat\n",
      "19 is youtube\n"
     ]
    }
   ],
   "source": [
    "x = np.load('../x_triple2token_dict.npy')\n",
    "y = pp.getlabel('../metadata.csv')\n",
    "\n",
    "num_index = np.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4322\n"
     ]
    }
   ],
   "source": [
    "print(num_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 150\n",
    "hidden_dim = 100\n",
    "num_layers = 5\n",
    "output_size = 20\n",
    "batch = 16\n",
    "lr = 0.001\n",
    "epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWE(\n",
      "  (embedding): Embedding(4323, 150)\n",
      "  (lstm): LSTM(150, 100, num_layers=5, batch_first=True, dropout=0.22, bidirectional=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv1d(1, 32, kernel_size=(1,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=3200, out_features=1000, bias=True)\n",
      "    (1): Linear(in_features=1000, out_features=20, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = cwe.CWE(num_index+1, hidden_dim, num_layers, input_size,output_size, batch).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2544, 900)\n",
      "torch.Size([2544])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,shuffle=True, random_state=1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x_data[idx]\n",
    "        y = self.y_data[idx]\n",
    "        return x, y\n",
    "\n",
    "train_dataset = CustomDataset(x_train,y_train)\n",
    "test_dataset = CustomDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True,drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch, shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 :  Loss: 0.30922311544418335\n",
      "epoch 20 :  Loss: 0.38475528359413147\n",
      "epoch 30 :  Loss: 0.2358551174402237\n",
      "epoch 40 :  Loss: 0.3647477924823761\n",
      "epoch 50 :  Loss: 0.17824171483516693\n",
      "epoch 60 :  Loss: 0.0013858855236321688\n",
      "epoch 70 :  Loss: 0.0001439579064026475\n",
      "epoch 80 :  Loss: 0.0057332213036715984\n",
      "epoch 90 :  Loss: 0.013013914227485657\n",
      "epoch 100 :  Loss: 0.0745667815208435\n",
      "epoch 110 :  Loss: 0.21265053749084473\n",
      "epoch 120 :  Loss: 0.07972748577594757\n",
      "epoch 130 :  Loss: 0.006724173203110695\n",
      "epoch 140 :  Loss: 0.01777603290975094\n",
      "epoch 150 :  Loss: 7.017593452474102e-05\n",
      "epoch 160 :  Loss: 0.0009433758677914739\n",
      "epoch 170 :  Loss: 0.00010281504364684224\n",
      "epoch 180 :  Loss: 0.024735799059271812\n",
      "epoch 190 :  Loss: 0.0002779499045573175\n",
      "epoch 200 :  Loss: 7.770962110953405e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(epoch):\n",
    "    for j,[data,label] in enumerate(train_loader):\n",
    "        label = label.type(torch.LongTensor)\n",
    "        x = data.to(device)\n",
    "        y = label.to(device)\n",
    "        outputs = model.forward(x)\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs, y)\n",
    "        \n",
    "        # 역전파 및 가중치 업데이트\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f'epoch {(i+1)} :  Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 92.78845977783203%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model_name = \"LCNN_ver12.pt\"\n",
    "total =0\n",
    "correct=0\n",
    "incorrect_num_correct = np.zeros(120)\n",
    "incorrect_num_answer = np.zeros(120)\n",
    "with torch.no_grad():\n",
    "    for image,label in test_loader:\n",
    "        x = image.to(device)\n",
    "        y= label.to(device)\n",
    "        output = model.forward(x)\n",
    "        \n",
    "        # torch.max함수는 (최댓값,index)를 반환 \n",
    "        _,output_index = torch.max(output,1)\n",
    "        \n",
    "        # 전체 개수 += 라벨의 개수\n",
    "        total += label.size(0)\n",
    "        \n",
    "        # 도출한 모델의 index와 라벨이 일치하면 correct에 개수 추가\n",
    "        correct += (output_index == y).sum().float()\n",
    "        \n",
    "        for i in range(len(y)):\n",
    "            if y[i]!=output_index[i]:\n",
    "                k = int(y[i].cpu().numpy())\n",
    "                incorrect_num_correct[k] += 1\n",
    "                incorrect_num_answer[int(output_index[i].cpu().numpy())]+=1\n",
    "\n",
    "    \n",
    "    # 정확도 도출\n",
    "    print(\"Accuracy of Test Data: {}%\".format(100*correct/total))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
